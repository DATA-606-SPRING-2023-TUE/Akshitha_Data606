{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33c3a1fb",
   "metadata": {
    "id": "33c3a1fb"
   },
   "source": [
    "# Project : H1-B Prediction Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4a89e1",
   "metadata": {
    "id": "9d4a89e1"
   },
   "source": [
    "## Aim :\n",
    "To predict the Case Status of the Visa application based on 6 year application data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c9701d",
   "metadata": {
    "id": "02c9701d"
   },
   "source": [
    "## Prediction Flow\n",
    "\n",
    "1. Import the required libraries.\n",
    "2. Understanding the data\n",
    "3. Cleaning the Data\n",
    "4. Combined SOC_NAMEs together for a common SOC_NAME_NEW\n",
    "5. EDA on the top companies with more number of applications and average salaries\n",
    "6. Identify Feature Importances.\n",
    "7. Applying LOgistic Regression, Decision Tree and Random Forest Classifier, GaussianNB, MLP Classifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb49f663",
   "metadata": {
    "id": "cb49f663"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from collections import Counter as c  \n",
    "from matplotlib.pyplot import plot  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb2650e",
   "metadata": {
    "id": "dfb2650e",
    "outputId": "ef5d75a4-1c74-46e1-b067-213829d7b513"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"h1b_kaggle.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2851b77",
   "metadata": {
    "id": "d2851b77",
    "outputId": "9f5bb68f-66e7-4ee5-91bf-52e521b9da9f"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c18c91a",
   "metadata": {
    "id": "8c18c91a",
    "outputId": "401d41f7-82aa-4f64-f483-6ff48c4399ea"
   },
   "outputs": [],
   "source": [
    "df.describe()\n",
    "\"\"\"Using df.describe() can be a quick way to get an idea of the distribution of data in a DataFrame and to identify potential issues such as missing data, outliers, and extreme values.\n",
    "It can also provide a starting point for more in-depth analysis and visualization of the data.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cdf435",
   "metadata": {
    "id": "b6cdf435",
    "outputId": "335be55e-4493-45e5-ea4a-083ae3018fc9"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae1b6a8",
   "metadata": {
    "id": "dae1b6a8",
    "outputId": "b5617fda-eda5-4269-beb9-c4f550f8a57f"
   },
   "outputs": [],
   "source": [
    "df.isna().sum()\n",
    "\n",
    "\"\"\"lon, lat and SOC_NAME has the highest number of null values. \n",
    "SOC_NAME stands for \"Standard Occupational Classification Name.\" It is a column in certain datasets \n",
    "that contain information about workers in the United States.\n",
    "The SOC system is used by the U.S. government to classify and track various types of jobs in the labor market.\n",
    "The SOC system defines over 800 detailed occupations, which are organized into 23 major groups.\n",
    "Each occupation is assigned a unique code and a corresponding job title.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4eed38",
   "metadata": {
    "id": "ed4eed38",
    "outputId": "40af10b2-2296-4f31-e08a-30a209a9ce56"
   },
   "outputs": [],
   "source": [
    "print(df['YEAR'].unique())    #Looking for the distinct years for the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5660aa",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddab38b2",
   "metadata": {
    "id": "ddab38b2"
   },
   "outputs": [],
   "source": [
    "df['EMPLOYER_NAME'] = df['EMPLOYER_NAME'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73632918",
   "metadata": {
    "id": "73632918",
    "outputId": "6b0377e2-3542-49bb-9564-4311299676b5"
   },
   "outputs": [],
   "source": [
    "df['YEAR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e70f1a",
   "metadata": {
    "id": "d7e70f1a"
   },
   "outputs": [],
   "source": [
    "df['YEAR'] = pd.to_numeric(df['YEAR'], errors='coerce')\n",
    "\n",
    "# find median of two columns\n",
    "median = np.nanmedian(df['YEAR'])\n",
    "\n",
    "# replace NaN values with median\n",
    "df['YEAR'] = df['YEAR'].fillna(median)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b07a4ae",
   "metadata": {},
   "source": [
    "### Updating the target variable into binary output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6619d1af",
   "metadata": {
    "id": "6619d1af",
    "outputId": "8997e928-3a71-49fc-aa87-b931d9750068"
   },
   "outputs": [],
   "source": [
    "df['CASE_STATUS'].value_counts() # I want the target variable to contain two simple values Certified or Denied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08d97d0",
   "metadata": {
    "id": "e08d97d0"
   },
   "outputs": [],
   "source": [
    "df = df.drop(df[df['CASE_STATUS'] == 'WITHDRAWN'].index)\n",
    "df['CASE_STATUS'] = df['CASE_STATUS'].replace({'CERTIFIED-WITHDRAWN': 'CERTIFIED',\n",
    "                                               'REJECTED': 'DENIED',\n",
    "                                               'INVALIDATED': 'DENIED',\n",
    "                                               'PENDING QUALITY AND COMPLIANCE REVIEW - UNASSIGNED': 'DENIED'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf4b65e",
   "metadata": {
    "id": "4cf4b65e"
   },
   "outputs": [],
   "source": [
    "df['SOC_NAME'] = df['SOC_NAME'].fillna('others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d9df54",
   "metadata": {
    "id": "c5d9df54",
    "outputId": "5168378e-5fa8-4c44-d906-ee1c243f1fb2"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "df['SOC_NAME_NEW'] = 'others'\n",
    "df['SOC_NAME_NEW'][df['SOC_NAME'].str.contains('CHIEF|EXECUTIVES')] = 'Executives'\n",
    "df['SOC_NAME_NEW'][df['SOC_NAME'].str.contains('Computer|Software|Developer|Cloud|Cybersecurity|Application')] = 'IT'\n",
    "df['SOC_NAME_NEW'][df['SOC_NAME'].str.contains('Chief|Management|MANAGERS')] = 'Manager'\n",
    "df['SOC_NAME_NEW'][df['SOC_NAME'].str.contains('Mechanical|Automotive|Mechatronics')] = 'Mechanical'\n",
    "df['SOC_NAME_NEW'][df['SOC_NAME'].str.contains('Sales|Market')] = 'Sales & Market'\n",
    "df['SOC_NAME_NEW'][df['SOC_NAME'].str.contains('FINANCIAL|Capitalist|Banker')] = 'Finance'\n",
    "df['SOC_NAME_NEW'][df['SOC_NAME'].str.contains('Public|Fundraising')] = 'P.R'\n",
    "df['SOC_NAME_NEW'][df['SOC_NAME'].str.contains('education|law')] = 'Administrative'\n",
    "df['SOC_NAME_NEW'][df['SOC_NAME'].str.contains('Auditors|Compliance')] = 'Audit'\n",
    "df['SOC_NAME_NEW'][df['SOC_NAME'].str.contains('Recruiters|Human')] = 'H.R'\n",
    "df['SOC_NAME_NEW'][df['SOC_NAME'].str.contains('Agricultural|Farm|Horticultural|Cultivation')] = 'Agriculture'\n",
    "df['SOC_NAME_NEW'][df['SOC_NAME'].str.contains('Construction|Architectural')] = 'Estate'\n",
    "df['SOC_NAME_NEW'][df['SOC_NAME'].str.contains('Forencsic|Health|Doctor|Medicine')] = 'Medical'\n",
    "df['SOC_NAME_NEW'][df['SOC_NAME'].str.contains('teachers|Professor')] = 'Education'\n",
    "# The str.contains() method used in the code is case-insensitive by default. \n",
    "# This means that it will match strings regardless of the case of the letters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785134c6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af37a7b",
   "metadata": {
    "id": "3af37a7b"
   },
   "outputs": [],
   "source": [
    "df['CASE_STATUS'].fillna(df['CASE_STATUS'].mode().iloc[0],inplace=True)\n",
    "df['SOC_NAME'].fillna(df['SOC_NAME'].mode().iloc[0],inplace=True)\n",
    "df['FULL_TIME_POSITION'].fillna(df['FULL_TIME_POSITION'].mode().iloc[0],inplace=True)\n",
    "df['YEAR'].fillna(df['YEAR'].mode().iloc[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2191c6",
   "metadata": {
    "id": "da2191c6",
    "outputId": "c4c4b81b-0d7a-4a79-93f3-93b5df90c92e"
   },
   "outputs": [],
   "source": [
    "df['PREVAILING_WAGE'].fillna(df['PREVAILING_WAGE'].median(),inplace=True)\n",
    "print(df['CASE_STATUS'].unique())\n",
    "print(df['YEAR'].unique())\n",
    "print(df['FULL_TIME_POSITION'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b971673",
   "metadata": {
    "id": "8b971673",
    "outputId": "d43bce38-1d5f-4396-af1b-b2668ef983b2"
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e1669",
   "metadata": {},
   "source": [
    "# Plotting/ Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ecd26e",
   "metadata": {},
   "source": [
    "## Top 10 Applicants in 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85311e14",
   "metadata": {
    "id": "85311e14",
    "outputId": "225c6fc0-52dd-4596-c0a9-e1a0ec4bc06c"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df2016 = df[df['YEAR'] == 2016]\n",
    "top_10_emp = df2016['EMPLOYER_NAME'].value_counts().head(10).reset_index() # Top 10 Employers\n",
    "top_10_emp.columns = ['EMPLOYER_NAME', 'Freq']\n",
    "top_10_emp = top_10_emp.sort_values(by='Freq', ascending=True) # sort values in descending order\n",
    "\n",
    "\n",
    "fig = px.bar(\n",
    "    data_frame=top_10_emp,\n",
    "    y=\"EMPLOYER_NAME\",\n",
    "    x=\"Freq\",\n",
    "    orientation=\"h\",\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    "    height=700,\n",
    "    labels={\"Freq\": \"Frequency\", \"EMPLOYER_NAME\": \"Employer Name\"},\n",
    "    title=\"Top 10 Applicants in 2016\"\n",
    ")\n",
    "\n",
    "fig.update_traces(marker_line_width=1)\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33678d4",
   "metadata": {},
   "source": [
    "## Top 10 Applicants in 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57206cdb",
   "metadata": {
    "id": "57206cdb",
    "outputId": "db815be0-1053-496f-8985-f9c7fe0aa2a5"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df2015 = df[df['YEAR'] == 2015]\n",
    "top_10_emp = df2015['EMPLOYER_NAME'].value_counts().head(10).reset_index() # Top 10 Employers\n",
    "top_10_emp.columns = ['EMPLOYER_NAME', 'Freq']\n",
    "top_10_emp = top_10_emp.sort_values(by='Freq', ascending=True) # sort values in descending order\n",
    "\n",
    "\n",
    "fig = px.bar(\n",
    "    data_frame=top_10_emp,\n",
    "    y=\"EMPLOYER_NAME\",\n",
    "    x=\"Freq\",\n",
    "    orientation=\"h\",\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    "    height=700,\n",
    "    labels={\"Freq\": \"Frequency\", \"EMPLOYER_NAME\": \"Employer Name\"},\n",
    "    title=\"Top 10 Applicants in 2015\"\n",
    ")\n",
    "\n",
    "fig.update_traces(marker_line_width=1)\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2679ff0",
   "metadata": {},
   "source": [
    "## Top 10 Applicants in 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddbf98a",
   "metadata": {
    "id": "8ddbf98a",
    "outputId": "b5a39235-f4e5-4bf4-bbd1-07dee6e088fb"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df2014 = df[df['YEAR'] == 2014]\n",
    "top_10_emp = df2014['EMPLOYER_NAME'].value_counts().head(10).reset_index() # Top 10 Employers\n",
    "top_10_emp.columns = ['EMPLOYER_NAME', 'Freq']\n",
    "top_10_emp = top_10_emp.sort_values(by='Freq', ascending=True) # sort values in descending order\n",
    "\n",
    "\n",
    "fig = px.bar(\n",
    "    data_frame=top_10_emp,\n",
    "    y=\"EMPLOYER_NAME\",\n",
    "    x=\"Freq\",\n",
    "    orientation=\"h\",\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    "    height=700,\n",
    "    labels={\"Freq\": \"Frequency\", \"EMPLOYER_NAME\": \"Employer Name\"},\n",
    "    title=\"Top 10 Applicants in 2014\"\n",
    ")\n",
    "\n",
    "fig.update_traces(marker_line_width=1)\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31498d67",
   "metadata": {
    "id": "31498d67"
   },
   "outputs": [],
   "source": [
    "top_emp = list(df['EMPLOYER_NAME'][df['YEAR'] >= 2015].groupby(df['EMPLOYER_NAME']).count().sort_values(ascending=False).head(10).index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afafa59c",
   "metadata": {
    "id": "afafa59c",
    "outputId": "d045f366-1a1a-4a85-b4c7-53627ce25ad0"
   },
   "outputs": [],
   "source": [
    "top_emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d57462",
   "metadata": {
    "id": "33d57462"
   },
   "outputs": [],
   "source": [
    "byempyear = df[['EMPLOYER_NAME', 'YEAR', 'PREVAILING_WAGE']][df['EMPLOYER_NAME'].isin(top_emp)].groupby([df['EMPLOYER_NAME'], df['YEAR']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5af2ddf",
   "metadata": {
    "id": "c5af2ddf",
    "outputId": "5e1016a8-051a-4c9c-c557-5175cdbf10a3"
   },
   "outputs": [],
   "source": [
    "byempyear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc15ead",
   "metadata": {},
   "source": [
    "# Number of Applications of Top 10 Applicants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb254a6",
   "metadata": {
    "id": "3bb254a6",
    "outputId": "4d1f2df7-11ef-464c-9fe2-d91ab745f42b"
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "markers=['circle','square','diamond','cross','x','triangle-up','triangle-down','triangle-left','triangle-right','star']\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for company in top_emp:\n",
    "    tmp = byempyear.count().loc[company]\n",
    "    fig.add_trace(go.Scatter(x=tmp.index.values, y=tmp[\"PREVAILING_WAGE\"].values, \n",
    "                              name=company, mode='lines+markers', marker=dict(symbol=markers[top_emp.index(company)], size=10),\n",
    "                              line=dict(width=2)))\n",
    "\n",
    "fig.update_layout(xaxis_title=\"Year\", yaxis_title=\"Number of Applications\",\n",
    "                  title_text=\"Number of Applications of Top 10 Applicants\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a954d29e",
   "metadata": {},
   "source": [
    "# Average Salary of Top 10 Applicants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e445b1da",
   "metadata": {
    "id": "e445b1da",
    "outputId": "f6acd5f6-153f-4771-eda0-562fb6a5e128"
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "markers=['circle','square','diamond','cross','x','triangle-up','triangle-down','triangle-left','triangle-right','star']\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for company in top_emp:\n",
    "    tmp = byempyear.mean().loc[company]\n",
    "    fig.add_trace(go.Scatter(x=tmp.index.values, y=tmp[\"PREVAILING_WAGE\"].values, \n",
    "                              name=company, mode='lines+markers', marker=dict(symbol=markers[top_emp.index(company)], size=10),\n",
    "                              line=dict(width=2)))\n",
    "\n",
    "fig.update_layout(xaxis_title=\"Year\", yaxis_title=\"Average Salary offered (USD)\",\n",
    "                  title_text=\"Average Salary of Top 10 Applicants\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9051c31c",
   "metadata": {},
   "source": [
    "## Number of Applications made for the Full Time Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d6a59a",
   "metadata": {
    "id": "70d6a59a",
    "outputId": "1e51a2d5-ba56-4a09-a87b-e6301262b699"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.histogram(df, x='FULL_TIME_POSITION', title='NUMBER OF APPLICATIONS MADE FOR THE FULL TIME POSITION')\n",
    "fig.update_xaxes(title='FULL TIME POSITION')\n",
    "fig.update_yaxes(title='NUMBER OF PETITIONS MADE')\n",
    "fig.update_traces(marker=dict(color='rgb(158,222,225)', line=dict(color='black', width=1.5)))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1020656",
   "metadata": {
    "id": "c1020656"
   },
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0', 'EMPLOYER_NAME','JOB_TITLE','WORKSITE', 'lon','lat'], axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed1ed28",
   "metadata": {
    "id": "bed1ed28",
    "outputId": "f5d5481d-3b37-4953-b131-e77944ab4a4d"
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7afc8ad",
   "metadata": {
    "id": "a7afc8ad",
    "outputId": "e76c48ce-dc90-4747-87df-2722fd09016c"
   },
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac168b7",
   "metadata": {
    "id": "dac168b7",
    "outputId": "fa288ecf-11ad-4d32-a700-35cd22a9e9ac"
   },
   "outputs": [],
   "source": [
    "df.CASE_STATUS.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c5ed00",
   "metadata": {},
   "source": [
    "## Target variable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15933a0",
   "metadata": {
    "id": "a15933a0",
    "outputId": "b42345e1-a775-4074-cbfe-e1cda015cc38"
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "df_count = df['CASE_STATUS'].value_counts()\n",
    "\n",
    "fig = go.Figure(data=[go.Bar(y=df_count.index, x=df_count.values, orientation='h', \n",
    "                             marker=dict(color='rgb(158,222,225)', line=dict(color='black', width=1.5)))])\n",
    "fig.update_layout(title=\"Target variable values\", yaxis_title=\"CASE STATUS\", xaxis_title=\"NUMBER OF PETITIONS MADE\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89af02e",
   "metadata": {},
   "source": [
    "## Number of applications made per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5722b68",
   "metadata": {
    "id": "a5722b68",
    "outputId": "2cfed8cb-f378-4b1f-8735-780061dbc59f"
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "df_year_count = df['YEAR'].value_counts()\n",
    "\n",
    "fig = go.Figure(data=[go.Bar(x=df_year_count.index, y=df_year_count.values, \n",
    "                             marker=dict(color='rgb(158,222,225)', line=dict(color='rgb(8,48,107)', width=1.5)))])\n",
    "fig.update_layout(title=\"NUMBER OF PETITIONS MADE PER YEAR\", xaxis_title=\"YEAR\", yaxis_title=\"NUMBER OF PETITIONS MADE\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fc1a4c",
   "metadata": {
    "id": "54fc1a4c"
   },
   "outputs": [],
   "source": [
    "df['CASE_STATUS_tar'] = df['CASE_STATUS'].map({'CERTIFIED' : 1,  'DENIED' : 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00140c26",
   "metadata": {
    "id": "00140c26",
    "outputId": "1bf0c48f-8b4a-4c1c-e706-0bdcf7b6ccc5"
   },
   "outputs": [],
   "source": [
    "df['CASE_STATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd28110",
   "metadata": {
    "id": "bdd28110",
    "outputId": "fce8dc4e-aa57-43d6-a2b5-2d6a5438a842"
   },
   "outputs": [],
   "source": [
    "df['FULL_TIME_POSITION'] = df['FULL_TIME_POSITION'].map({'N' : 0, 'Y' : 1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d43199",
   "metadata": {
    "id": "a6d43199",
    "outputId": "e10f2400-4436-4de3-9ed2-1ae22fd171ad"
   },
   "outputs": [],
   "source": [
    "df['SOC_NAME_NEW'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa18ef44",
   "metadata": {
    "id": "fa18ef44"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df.SOC_NAME_NEW)\n",
    "df['SOC_N']=le.transform(df['SOC_NAME_NEW']) \n",
    "#Convert the categorical variable \"SOC_NAME_NEW\" in the DataFrame \"df\" into numerical labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba271880",
   "metadata": {
    "id": "ba271880",
    "outputId": "531a4c39-e659-450d-9341-29b15255f30b"
   },
   "outputs": [],
   "source": [
    "group = df.groupby('SOC_NAME_NEW')\n",
    "df2 = group.apply(lambda x: x['SOC_N'].unique())\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1f0d83",
   "metadata": {
    "id": "6b1f0d83"
   },
   "outputs": [],
   "source": [
    "df = df.drop(['SOC_NAME','SOC_NAME_NEW','CASE_STATUS'], axis=1)\n",
    "df = df.rename(columns={'CASE_STATUS_tar': 'CASE_STATUS'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49926b9",
   "metadata": {
    "id": "e49926b9",
    "outputId": "8fb4f1fa-8923-4252-d8eb-945b787f1614"
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acb48be",
   "metadata": {
    "id": "6acb48be",
    "outputId": "c8cd6959-e427-4061-ed1a-cfd2416e124a"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), annot=True, cmap=\"RdBu\", annot_kws={\"size\":9},linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b62402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurecols =['FULL_TIME_POSITION','PREVAILING_WAGE','YEAR','SOC_N']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e53e60a",
   "metadata": {},
   "source": [
    "## Applying Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47a3d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(df, columns=featurecols)\n",
    "y = pd.DataFrame(df, columns=[\"CASE_STATUS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd4582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39be608",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.ravel(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa409cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "LogReg = LogisticRegression()\n",
    "LogReg.fit(x_train, y_train)\n",
    "y_pred = LogReg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad46929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6709f6d",
   "metadata": {},
   "source": [
    "## Applying Z score method to remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579a921",
   "metadata": {
    "id": "a579a921"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Define the feature columns\n",
    "featurecols = [\"FULL_TIME_POSITION\", \"PREVAILING_WAGE\", \"YEAR\", \"SOC_N\"]\n",
    "\n",
    "# Create X and y DataFrames\n",
    "X = pd.DataFrame(df, columns=featurecols)\n",
    "y = pd.DataFrame(df, columns=[\"CASE_STATUS\"])\n",
    "\n",
    "# Calculate the z-scores for each feature\n",
    "z_scores = stats.zscore(X)\n",
    "\n",
    "# Define the z-score threshold for outliers\n",
    "z_thresh = 3\n",
    "\n",
    "# Create a Boolean mask for rows with z-scores within the threshold\n",
    "outlier_mask = (abs(z_scores) <= z_thresh).all(axis=1)\n",
    "\n",
    "# Create a new DataFrame without outliers\n",
    "X_no_outliers = X[outlier_mask]\n",
    "y_no_outliers = y[outlier_mask]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55f65c4",
   "metadata": {
    "id": "b55f65c4"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_no_outliers, y_no_outliers, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3c07e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.ravel(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de6a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653fb19b",
   "metadata": {
    "id": "653fb19b"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "LogReg = LogisticRegression()\n",
    "LogReg.fit(x_train, y_train)\n",
    "y_pred = LogReg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb48dac9",
   "metadata": {
    "id": "fb48dac9",
    "outputId": "429d51ea-0a2c-483e-9718-0765e9331508"
   },
   "outputs": [],
   "source": [
    "LogReg.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf20484c",
   "metadata": {
    "id": "bf20484c",
    "outputId": "15595018-66d4-4493-8e67-f0be73144e57"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(0.95)\n",
    "X_pca = pca.fit_transform(X)\n",
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e922ef8",
   "metadata": {
    "id": "5e922ef8"
   },
   "outputs": [],
   "source": [
    "\n",
    "x_pca_train, x_pca_test, y_train, y_test = train_test_split(X_pca, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b67c5d",
   "metadata": {
    "id": "62b67c5d"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "LogReg = LogisticRegression()\n",
    "LogReg.fit(x_pca_train, y_train.values.ravel())\n",
    "y_pred = LogReg.predict(x_pca_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7c0449",
   "metadata": {
    "id": "df7c0449",
    "outputId": "1f3f5b60-9e82-4a10-f76c-3ff823bf52f2"
   },
   "outputs": [],
   "source": [
    "LogReg.score(x_pca_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbce6fe2",
   "metadata": {
    "id": "bbce6fe2",
    "outputId": "1ff57a08-b494-4540-fed1-77b27bb8be8b"
   },
   "outputs": [],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1348d68d",
   "metadata": {
    "id": "1348d68d",
    "outputId": "e1ee594d-92d8-49d0-9657-9bebcb7e292b"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab040dd",
   "metadata": {
    "id": "0ab040dd",
    "outputId": "46409314-3f1a-4d6c-d2c4-127beef04c1d"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77685917",
   "metadata": {
    "id": "77685917"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df.CASE_STATUS==1]\n",
    "df_minority = df[df.CASE_STATUS==0]\n",
    "\n",
    "# Upsample minority class using SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X_smote, y_smote = smote.fit_resample(X, y)\n",
    "\n",
    "# Upsample minority class using random oversampling\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=len(df_majority),  # to match majority class\n",
    "                                 random_state=42)  # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                   replace=True,    # sample without replacement\n",
    "                                   n_samples=len(df_minority),  # to match minority class\n",
    "                                   random_state=42)  # reproducible results\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92beaed",
   "metadata": {},
   "source": [
    "## After applying Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d367e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features and target variable\n",
    "X = df_upsampled.drop('CASE_STATUS', axis=1)\n",
    "y = df_upsampled['CASE_STATUS']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the logistic regression model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Train the model on the training set\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model using accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680c6aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55abb91",
   "metadata": {},
   "source": [
    "## Applying downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9546e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features and target variable\n",
    "X = df_downsampled.drop('CASE_STATUS', axis=1)\n",
    "y = df_downsampled['CASE_STATUS']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the logistic regression model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Train the model on the training set\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model using accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705cc517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cd32a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cef730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(confusion_matrix,annot=True)\n",
    "plt.xlabel('y_pred')\n",
    "plt.ylabel('y_test')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a64253e",
   "metadata": {
    "id": "9a64253e",
    "outputId": "05b3e9b6-bd48-4e6a-fe56-e1f12c284f5b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# Separate the features and target variable\n",
    "X = df_upsampled.drop('CASE_STATUS', axis=1)\n",
    "y = df_upsampled['CASE_STATUS']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the logistic regression model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Train the model on the training set\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model using accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd23313",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1948b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Separate the features and target variable\n",
    "X = df_upsampled.drop('CASE_STATUS', axis=1)\n",
    "y = df_upsampled['CASE_STATUS']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a decision tree classifier on the training set\n",
    "model_dt = DecisionTreeClassifier()\n",
    "model_dt.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_dt = model_dt.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model on the testing set\n",
    "acc = accuracy_score(y_test, y_pred_dt)\n",
    "prec = precision_score(y_test, y_pred_dt)\n",
    "recall = recall_score(y_test, y_pred_dt)\n",
    "f1 = f1_score(y_test, y_pred_dt)\n",
    "\n",
    "print(\"accuracy_score : \", acc)\n",
    "print(\"precision_score : \", prec)\n",
    "print(\"recall_score : \", recall)\n",
    "print(\"f1_score : \", f1)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03ad227",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1924801",
   "metadata": {
    "id": "f1924801",
    "outputId": "c3334137-3d4e-4dbb-dfc3-1c91109ce77b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Separate the features and target variable\n",
    "X = df_upsampled.drop('CASE_STATUS', axis=1)\n",
    "y = df_upsampled['CASE_STATUS']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Gradient Boosting classifier on the training set\n",
    "model_gb = GradientBoostingClassifier()\n",
    "model_gb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_gb = model_gb.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model on the testing set\n",
    "acc = accuracy_score(y_test, y_pred_gb)\n",
    "prec = precision_score(y_test, y_pred_gb)\n",
    "recall = recall_score(y_test, y_pred_gb)\n",
    "f1 = f1_score(y_test, y_pred_gb)\n",
    "\n",
    "print(\"accuracy_score : \", acc)\n",
    "print(\"precision_score : \", prec)\n",
    "print(\"recall_score : \", recall)\n",
    "print(\"f1_score : \", f1)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "print(classification_report(y_test, y_pred_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ee9d65",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b026c70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Separate the features and target variable\n",
    "X = df_upsampled.drop('CASE_STATUS', axis=1)\n",
    "y = df_upsampled['CASE_STATUS']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier on the training set\n",
    "model_rf = RandomForestClassifier()\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model on the testing set\n",
    "acc = accuracy_score(y_test, y_pred_rf)\n",
    "prec = precision_score(y_test, y_pred_rf)\n",
    "recall = recall_score(y_test, y_pred_rf)\n",
    "f1 = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"accuracy_score : \", acc)\n",
    "print(\"precision_score : \", prec)\n",
    "print(\"recall_score : \", recall)\n",
    "print(\"f1_score : \", f1)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e1faab",
   "metadata": {},
   "source": [
    "## KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebc48b8",
   "metadata": {
    "id": "bebc48b8",
    "outputId": "b1ce9a89-7c25-4bd3-f215-c62668913e0a"
   },
   "outputs": [],
   "source": [
    "# Separate the features and target variable\n",
    "X = df_upsampled.drop('CASE_STATUS', axis=1)\n",
    "y = df_upsampled['CASE_STATUS']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a KNN classifier object\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the KNN classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model using accuracy score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "acc = accuracy_score(y_test, y_pred_knn)\n",
    "prec = precision_score(y_test, y_pred_knn)\n",
    "recall = recall_score(y_test, y_pred_knn)\n",
    "f1 = f1_score(y_test, y_pred_knn)\n",
    "print(\"accuracy_score : \", acc)\n",
    "print(\"precision_score : \", prec)\n",
    "print(\"recall_score : \", recall)\n",
    "print(\"f1_score : \", f1)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af471d49",
   "metadata": {},
   "source": [
    "## Gaussian NB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e039af",
   "metadata": {
    "id": "84e039af",
    "outputId": "c8e82e26-3917-4d7c-c852-9524da5369c8"
   },
   "outputs": [],
   "source": [
    "# Separate the features and target variable\n",
    "X = df_upsampled.drop('CASE_STATUS', axis=1)\n",
    "y = df_upsampled['CASE_STATUS']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Naive Bayes classifier object\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model using accuracy score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "acc = accuracy_score(y_test, y_pred_nb)\n",
    "prec = precision_score(y_test, y_pred_nb)\n",
    "recall = recall_score(y_test, y_pred_nb)\n",
    "f1 = f1_score(y_test, y_pred_nb)\n",
    "print(\"accuracy_score : \", acc)\n",
    "print(\"precision_score : \", prec)\n",
    "print(\"recall_score : \", recall)\n",
    "print(\"f1_score : \", f1)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "print(classification_report(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78d3d77",
   "metadata": {},
   "source": [
    "## AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873488e9",
   "metadata": {
    "id": "873488e9",
    "outputId": "06810c40-16a0-4d1c-e6f6-05c0e34a0a36"
   },
   "outputs": [],
   "source": [
    "# Separate the features and target variable\n",
    "X = df_upsampled.drop('CASE_STATUS', axis=1)\n",
    "y = df_upsampled['CASE_STATUS']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an AdaBoost classifier object\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the AdaBoost classifier\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_ada = ada.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model using accuracy score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "acc = accuracy_score(y_test, y_pred_ada)\n",
    "prec = precision_score(y_test, y_pred_ada)\n",
    "recall = recall_score(y_test, y_pred_ada)\n",
    "f1 = f1_score(y_test, y_pred_ada)\n",
    "print(\"accuracy_score : \", acc)\n",
    "print(\"precision_score : \", prec)\n",
    "print(\"recall_score : \", recall)\n",
    "print(\"f1_score : \", f1)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "print(classification_report(y_test, y_pred_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0d51a7",
   "metadata": {},
   "source": [
    "## XG Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d638c21",
   "metadata": {
    "id": "2d638c21",
    "outputId": "496be0e4-122a-4de3-a306-6d7aa9429fe8"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Separate the features and target variable\n",
    "X = df_upsampled.drop('CASE_STATUS', axis=1)\n",
    "y = df_upsampled['CASE_STATUS']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train an XGBoost classifier on the training set\n",
    "model_xgb = xgb.XGBClassifier()\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model on the testing set\n",
    "acc = accuracy_score(y_test, y_pred_xgb)\n",
    "prec = precision_score(y_test, y_pred_xgb)\n",
    "recall = recall_score(y_test, y_pred_xgb)\n",
    "f1 = f1_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"accuracy_score : \", acc)\n",
    "print(\"precision_score : \", prec)\n",
    "print(\"recall_score : \", recall)\n",
    "print(\"f1_score : \", f1)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88f0157",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7292154d",
   "metadata": {},
   "source": [
    "### The key idea behind Stacking is to leverage the strengths of each individual model and to reduce their weaknesses by combining their predictions. This can lead to a more accurate and robust predictive model than any single model on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510ad464",
   "metadata": {
    "id": "510ad464"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Define the base models\n",
    "base_models = [\n",
    "    ('dt', DecisionTreeClassifier(random_state=42)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "   \n",
    "]\n",
    "\n",
    "# Define the meta-model\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Create the stacking classifier\n",
    "stacking = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "\n",
    "# Train the stacking classifier\n",
    "stacking.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = stacking.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
